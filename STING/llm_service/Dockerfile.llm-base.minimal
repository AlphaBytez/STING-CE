FROM python:3.10.16-slim

WORKDIR /app

# ========================================
# ARCHIVED: This Dockerfile is no longer used
# STING uses Ollama/external LLM services for inference
# Kept for reference only
# ========================================

# Copy requirements first
COPY requirements.txt .

# Install Python dependencies only - skip system packages
RUN pip install --no-cache-dir -r requirements.txt || \
    pip install --no-cache-dir --trusted-host pypi.org --trusted-host files.pythonhosted.org -r requirements.txt

# Copy utilities
COPY utils/ /app/utils

# ========================================
# REMOVED: PyTorch and ML libraries (10GB+ CUDA downloads)
# All LLM inference now via Ollama or external-ai service
# ========================================
# RUN pip install --no-cache-dir torch torchvision transformers accelerate sentencepiece

# Install only lightweight API dependencies
RUN pip install --no-cache-dir fastapi uvicorn || \
    pip install --no-cache-dir --trusted-host pypi.org --trusted-host files.pythonhosted.org \
    fastapi uvicorn

# Create necessary directories
RUN mkdir -p /app/models /app/cache

# Set environment variables
ENV PYTHONPATH=/app

# Copy scripts
COPY ./detect_platform.sh ./server.py ./

# Make scripts executable using Python instead of chmod
RUN python -c "import os; os.chmod('detect_platform.sh', 0o755)"

# This is just a base image
CMD ["/bin/true"]